{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n",
      "(40200, 784) (19800, 784)\n",
      "(40200, 10) (19800, 10)\n"
     ]
    }
   ],
   "source": [
    "raw_train_images = scipy.io.loadmat(\"dataset/train.mat\")['train_images']\n",
    "raw_train_labels = scipy.io.loadmat(\"dataset/train.mat\")['train_labels']\n",
    "shuff = np.random.choice(len(raw_train_labels), len(raw_train_labels), False)\n",
    "raw_train_images = scipy.io.loadmat(\"dataset/train.mat\")['train_images'].T.reshape(60000,784)[shuff]\n",
    "raw_train_labels = scipy.io.loadmat(\"dataset/train.mat\")['train_labels'].reshape(60000,)[shuff]\n",
    "raw_train_labels = pd.get_dummies(pd.Series(raw_train_labels)).values\n",
    "\n",
    "print(raw_train_images.shape, raw_train_labels.shape)\n",
    "tX, tXt, ty, tyt = train_test_split(raw_train_images, raw_train_labels, test_size=0.33)\n",
    "print(tX.shape, tXt.shape)\n",
    "print(ty.shape, tyt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(scipy.io.loadmat(\"dataset/test.mat\")['test_images'].T.shape)\n",
    "kaggleTest = scipy.io.loadmat(\"dataset/test.mat\")['test_images'].T.reshape(10000,784)\n",
    "print(kaggleTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_bias(in_val):\n",
    "    return np.vstack([in_val, np.ones(len(in_val[0]))])\n",
    "\n",
    "def initialize_layer(input_dim, output_dim, seed):\n",
    "    np.random.seed(seed)\n",
    "    z = np.random.normal(0,0.01,output_dim)\n",
    "    y = np.random.normal(0,0.01,output_dim)\n",
    "    w = np.random.normal(0,0.01,(input_dim, output_dim))\n",
    "    \n",
    "    bz = np.append(np.random.normal(0,0.01,output_dim), 1)\n",
    "    by = np.append(np.random.normal(0,0.01,output_dim), 1)\n",
    "    bw = add_bias(np.random.normal(0,0.01,(input_dim, output_dim)))\n",
    "    return z, bz, y, by, w, bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_loss_raw(y,y_2): return np.power((y - y_2), 2)\n",
    "def squared_loss_deriv_raw(y,y_2): return (y_2 - y)\n",
    "squared_loss = np.vectorize(squared_loss_raw)\n",
    "squared_loss_deriv = np.vectorize(squared_loss_deriv_raw)\n",
    "\n",
    "def calc_dEdz2(y_2, y, cost_deriv):\n",
    "    return np.diag(\n",
    "        np.multiply(y_2, np.subtract(1, y_2))\n",
    "    ).dot(cost_deriv(y, y_2))\n",
    "\n",
    "def calc_dEdz1(z_1, w_2, dEdz2):\n",
    "    return np.diag(\n",
    "        np.subtract(1, np.power(np.tanh(z_1), 2))\n",
    "    ).dot(w_2).dot(dEdz2)\n",
    "\n",
    "def predictNN(seq, X):\n",
    "    temp = X\n",
    "    for comm in seq:\n",
    "        if \"func\" in str(type(comm)):\n",
    "            temp = comm(temp)\n",
    "        else:\n",
    "            temp = temp.dot(comm)\n",
    "    return temp.argmax(axis=1)\n",
    "\n",
    "def scoreNN(seq, X, y):\n",
    "    preds = predictNN(seq, X)\n",
    "    y_vals = y.argmax(axis=1)\n",
    "    return sum(preds != y_vals)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Initialization\n",
      "Iterations per Epoch: 100\n",
      "------------------------- Training\n",
      "Starting Epoch Number 0\n",
      "Finished Epoch 0\n",
      "Training Error 0.924527363184\n",
      "Validation Error 0.923080808081\n",
      "--------------------\n",
      "Starting Epoch Number 1\n",
      "Finished Epoch 1\n",
      "Training Error 0.932985074627\n",
      "Validation Error"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"hidden_layer_size\": 200,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"epochs\": 5,\n",
    "    \"epoch_length\": 100,\n",
    "    \n",
    "    \"cost_func\": squared_loss,\n",
    "    \"cost_func_deriv\": squared_loss_deriv\n",
    "}\n",
    "\n",
    "def trainNN(X, y, Xt, yt, params, seed=100):\n",
    "    hl_size = params['hidden_layer_size']\n",
    "    lr = params['learning_rate']\n",
    "    epoch_length = params.get('epoch_length', len(X))\n",
    "    feature_dim = len(tX[0])\n",
    "    output_dim = len(y[0])\n",
    "    \n",
    "    cost = params['cost_func']\n",
    "    cost_deriv = params['cost_func_deriv']\n",
    "\n",
    "    z_1, bz_1, y_1, by_1, w_1, bw_1 = initialize_layer(feature_dim, hl_size, seed)\n",
    "    z_2, bz_2, y_2, by_2, w_2, bw_2 = initialize_layer(hl_size, output_dim, seed)\n",
    "    \n",
    "    dEdw2 = np.zeros((hl_size, output_dim))\n",
    "    dEdw1 = np.zeros((feature_dim, hl_size))\n",
    "    print(\"-\"*25, \"Initialization\") \n",
    "    print(\"Iterations per Epoch:\", epoch_length)\n",
    "    print(\"-\"*25, \"Training\")\n",
    "\n",
    "    for epoch in range(params['epochs']):\n",
    "        print(\"Starting Epoch Number\", epoch)\n",
    "        for _ in range(epoch_length):\n",
    "            training_point = int(np.random.choice(len(y), 1))\n",
    "            y_0 = X[training_point]\n",
    "            by_0 = np.append(y_0, 1)\n",
    "            truth = y[training_point]\n",
    "\n",
    "            # forward pass\n",
    "            y_0.dot(w_1, out=z_1)\n",
    "            np.tanh(z_1, out=y_1)\n",
    "            y_1.dot(w_2, out=z_2)\n",
    "            y_2 = 1 / (1 + np.exp(-1 * z_2)) # make it better?\n",
    "\n",
    "            #cache\n",
    "            dEdz2 = calc_dEdz2(y_2, truth, cost_deriv)\n",
    "            dEdz1 = calc_dEdz1(z_1, w_2, dEdz2)\n",
    "\n",
    "            #backprop\n",
    "            np.outer(y_1, dEdz2.T, out=dEdw2) # l2 weights\n",
    "            np.outer(y_0, dEdz1.T, out=dEdw1)# l1 weights\n",
    "\n",
    "            #updates\n",
    "            w_1 = np.subtract(w_1, np.multiply(lr, dEdw1))\n",
    "            w_2 = np.subtract(w_2, np.multiply(lr, dEdw2))\n",
    "            \n",
    "        prediction_sequence = [w_1, np.tanh, w_2, np.vectorize(lambda x: 1 / 1 + np.exp(-1 * x))]\n",
    "        print(\"Finished Epoch\", epoch)\n",
    "        train_score = scoreNN(prediction_sequence, X, y)\n",
    "        print(\"Training Error\", train_score)\n",
    "        validation_score = scoreNN(prediction_sequence, Xt, yt)\n",
    "        print(\"Validation Error\", validation_score)\n",
    "        print(\"-\"*20)\n",
    "        \n",
    "    return [w_1, np.tanh, w_2, np.vectorize(lambda x: 1 / 1 + np.exp(-1 * x))]\n",
    "\n",
    "seq = trainNN(tX, ty, tXt, tyt, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "kaggle_out = pd.DataFrame(predictNN(seq, kaggleTest)).reset_index()\n",
    "kaggle_out.columns = ['Id', 'Category']\n",
    "kaggle_out.Id = kaggle_out.Id + 1\n",
    "t = str(datetime.datetime.now())\n",
    "fname = \"Kaggle prediction \" + t + \".csv\"\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_out.to_csv(fname,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
